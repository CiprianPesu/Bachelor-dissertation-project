{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceac47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b637248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datasets/Stem-Cuvinte-Eliminate/test-punct-stop-stem-1000.csv\")\n",
    "df=df.dropna()\n",
    "#df=df.drop([\"news_title\",\"url\",\"reddit_title\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a93490",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e24129",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_list = {r\"i'm\": 'i am',\n",
    "                r\"'re\": ' are',\n",
    "                r\"let’s\": 'let us',\n",
    "                r\"'s\":  ' is',\n",
    "                r\"'ve\": ' have',\n",
    "                r\"can't\": 'can not',\n",
    "                r\"cannot\": 'can not',\n",
    "                r\"shan’t\": 'shall not',\n",
    "                r\"n't\": ' not',\n",
    "                r\"'d\": ' would',\n",
    "                r\"'ll\": ' will',\n",
    "                r\"'scuse\": 'excuse',\n",
    "                ',': ' ,',\n",
    "                '.': ' .',\n",
    "                '!': ' !',\n",
    "                '?': ' ?',\n",
    "                '\\s+': ' '}\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    for s in replace_list:\n",
    "        text = text.replace(s, replace_list[s])\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['text'].apply(lambda p: clean_text(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a56d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_len = X_train.apply(lambda p: len(p.split(' ')))\n",
    "max_phrase_len = phrase_len.max()\n",
    "print('max phrase len: {0}'.format(max_phrase_len))\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.hist(phrase_len, alpha = 0.2, density = True)\n",
    "plt.xlabel('phrase len')\n",
    "plt.ylabel('probability')\n",
    "plt.grid(alpha = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7aff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b639817",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=[]\n",
    "for i in range(0,len(y_train)):\n",
    "    train_labels.append([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(y_train)):\n",
    "    if y_train[i] == 0:\n",
    "        train_labels[i][0]=1\n",
    "    else:\n",
    "        train_labels[i][1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adb7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58af67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44de96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen = max_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3005899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('./Model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ccc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./Model92/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
