{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datasets/Cuvinte-Eliminate/train-punct-stop-1000.csv\")\n",
    "df=df.dropna()\n",
    "df=df.sample(n=2000000)\n",
    "#df=df.drop([\"news_title\",\"url\",\"reddit_title\"],axis=1)\n",
    "df_train=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d11fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_len = X_train.apply(lambda p: len(p.split(' ')))\n",
    "max_phrase_len = phrase_len.max()\n",
    "print('max phrase len: {0}'.format(max_phrase_len))\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.hist(phrase_len, alpha = 0.2, density = True)\n",
    "plt.xlabel('phrase len')\n",
    "plt.ylabel('probability')\n",
    "plt.grid(alpha = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb5e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd49b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=[]\n",
    "for i in range(0,len(y_train)):\n",
    "    train_labels.append([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac002f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7abc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(y_train)):\n",
    "    if y_train[i] == 0:\n",
    "        train_labels[i][0]=1\n",
    "    else:\n",
    "        train_labels[i][1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ce367",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 16384\n",
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen = max_phrase_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22060e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0])\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim = max_words, output_dim = 256, input_length = max_phrase_len))\n",
    "model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(128, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(2, activation = 'softmax'))\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb429136",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_lstm.fit(\n",
    "    X_train,\n",
    "    train_labels,\n",
    "    validation_split = 0.1,\n",
    "    epochs = 8,\n",
    "    batch_size = 512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e25a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train loss'),\n",
    "plt.plot(history.history['val_loss'], label='val loss'),\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Cross-entropy loss\"),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60379d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    plt.plot(history.history['accuracy'], label='train accuracy'),\n",
    "    plt.plot(history.history['val_accuracy'], label='val accuracy'),\n",
    "    plt.xlabel(\"epoch\"),\n",
    "    plt.ylabel(\"accuracy\"),\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ca0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.save('./Model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b25133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47f9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc478e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
