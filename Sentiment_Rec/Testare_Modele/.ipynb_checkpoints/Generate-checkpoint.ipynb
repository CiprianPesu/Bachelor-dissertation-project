{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222e4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "from transformers import AdamW\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4effb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "  for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))\n",
    "else:\n",
    "  print(\"You are running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3bed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0d75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datasets/Stem-Cuvinte-Eliminate/train-punct-stop-stem-200.csv\")\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f623596e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>sound track beauti paint mind well would recom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>im read lot review say best game soundtrack fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>soundtrack favorit music time hand intens sad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>truli like soundtrack enjoy video game music p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>youv play game know divin music everi singl so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          2  sound track beauti paint mind well would recom...\n",
       "1          2  im read lot review say best game soundtrack fi...\n",
       "2          2  soundtrack favorit music time hand intens sad ...\n",
       "3          2  truli like soundtrack enjoy video game music p...\n",
       "4          2  youv play game know divin music everi singl so..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3a8b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e903850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poz=df[df['sentiment'] == 1]\n",
    "df_neg=df[df['sentiment'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e9a776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poz=df_poz.sample(10000)\n",
    "df_neg=df_neg.sample(10000)\n",
    "df = pd.concat([df_poz,df_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c66935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57097</th>\n",
       "      <td>1</td>\n",
       "      <td>midst read age chao 1 right found book excit d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068253</th>\n",
       "      <td>1</td>\n",
       "      <td>read book immedi finish first kill father auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309518</th>\n",
       "      <td>1</td>\n",
       "      <td>ive alway militari aviat buff grow 60 ive seen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245798</th>\n",
       "      <td>1</td>\n",
       "      <td>overal book introduc framework invest accur de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271753</th>\n",
       "      <td>1</td>\n",
       "      <td>wolv bear real page turner author great writer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text\n",
       "57097            1  midst read age chao 1 right found book excit d...\n",
       "1068253          1  read book immedi finish first kill father auto...\n",
       "1309518          1  ive alway militari aviat buff grow 60 ive seen...\n",
       "245798           1  overal book introduc framework invest accur de...\n",
       "1271753          1  wolv bear real page turner author great writer..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d11fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "N_EPOCHS = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "103f3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =df.text\n",
    "X_test =df.text\n",
    "y_train = df.sentiment\n",
    "y_test = df.sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f509f2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = X_train.apply(lambda s: len([x for x in s.split()])).max()\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58211017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First paragraph: '57097    midst read age chao 1 right found book excit d...\n",
      "Name: text, dtype: object'\n",
      "Input ids: [101, 12930, 3191, 2287, 22455, 1015, 2157, 2179, 2338, 4654, 26243, 3697, 2404, 2175, 3637, 2151, 2239, 3037, 12170, 16558, 2594, 2010, 29469, 6811, 2010, 29469, 2755, 3054, 19422, 2789, 2010, 29469, 2338, 2442, 3191, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "#tokenize the text (padding to max sequence in batch)\n",
    "train_encodings = tokenizer(list(X_train.values), truncation=True, padding=\"max_length\", max_length=128)\n",
    "test_encodings = tokenizer(list(X_test.values), truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "#print the first paragraph and it transformation\n",
    "print(f'First paragraph: \\'{X_train[:1]}\\'')\n",
    "print(f'Input ids: {train_encodings[\"input_ids\"][0]}')\n",
    "print(f'Attention mask: {train_encodings[\"attention_mask\"][0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3363dca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 12:19:51.630785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 12:19:51.638697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 12:19:51.639107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 12:19:51.639969: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-21 12:19:51.640649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 12:19:51.641045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 12:19:51.641650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 12:19:52.098947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 12:19:52.099239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 12:19:52.099479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 12:19:52.099696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3368 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings),\n",
    "                                                    list(y_train.values)))\n",
    "\n",
    "#test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings),\n",
    " #                                                   list(y_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b87b37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 12:19:55.665557: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_layer_norm', 'vocab_projector', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_19', 'pre_classifier', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "optimizerr = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "losss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) # Computes the crossentropy loss between the labels and predictions. \n",
    "model.compile(optimizer=optimizerr,                                     \n",
    "              loss=losss,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0497d699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7faf4a531ac0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7faf4a531ac0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "813/813 [==============================] - 426s 512ms/step - loss: 0.4440 - accuracy: 0.7906\n",
      "Epoch 2/3\n",
      "813/813 [==============================] - 426s 523ms/step - loss: 0.2684 - accuracy: 0.8905\n",
      "Epoch 3/3\n",
      "813/813 [==============================] - 431s 530ms/step - loss: 0.1445 - accuracy: 0.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fae3d956b80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset.shuffle(len(X_train)).batch(BATCH_SIZE), \n",
    "          epochs=N_EPOCHS,\n",
    "          batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5612f227",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_95469/1833678899.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_dataset.shuffle(len(X_test)).batch(BATCH_SIZE), return_dict=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82f96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dd49b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(text_list, model, tokenizer):\n",
    "  \"\"\"\n",
    "  To get array with predicted probabilities for 0 - instructions, 1- ingredients classes \n",
    "  for each paragraph in the list of strings\n",
    "  :param text_list: list[str]\n",
    "  :param model: transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification\n",
    "  :param tokenizer: transformers.models.distilbert.tokenization_distilbert.DistilBertTokenizer\n",
    "  :return res: numpy.ndarray\n",
    "  \"\"\"\n",
    "     \n",
    "  encodings = tokenizer(text_list, max_length=MAX_LEN, truncation=True, padding=True)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((dict(encodings))) \n",
    "  preds = model.predict(dataset.batch(1)).logits\n",
    "  res = tf.nn.softmax(preds, axis=1).numpy()\n",
    "    \n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc478e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05632595, 0.943674  ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string1 = [\"this is good\"]\n",
    "predict_proba(string1, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33689e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints-13000/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_until_layer(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73dd22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
