{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a6b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import glob\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3112d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter=PorterStemmer()\n",
    "stopwords=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y']\n",
    "import pickle\n",
    "with open('tokenizer-200-nou.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d9e5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punct(a):        \n",
    "    return a.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def clean_stop(a):\n",
    "    a_token=a.split()\n",
    "    \n",
    "    str1=\"\"\n",
    "    for tk in a_token:\n",
    "        if tk in stopwords:\n",
    "            continue\n",
    "        else:\n",
    "            str1 += tk+\" \"\n",
    "            \n",
    "    return str1\n",
    "\n",
    "def clean_stem(a):\n",
    "    a_token=a.split()\n",
    "    \n",
    "    str1=\"\"\n",
    "    for tk in a_token:\n",
    "            str1 += porter.stem(tk)+\" \"\n",
    "            \n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82a200d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "---Stiri Pozitive---\n",
      "Stiri_pozitive/34.txt  0.3690533625244191     0.6309466321811531\n",
      "Stiri_pozitive/12.txt  0.4835854531959333     0.5164145446838216\n",
      "Stiri_pozitive/41.txt  0.38947495091706513     0.6105250611901283\n",
      "Stiri_pozitive/11.txt  0.4562814434369405     0.5437185571591059\n",
      "Stiri_pozitive/31.txt  0.39228916120414853     0.6077108356963705\n",
      "Stiri_pozitive/3.txt  0.369318414816999     0.6306815831388674\n",
      "Stiri_pozitive/39.txt  0.43881500472447704     0.561184992532021\n",
      "Stiri_pozitive/17.txt  0.37451187582352224     0.625488119553297\n",
      "Stiri_pozitive/8.txt  0.3003110231546965     0.6996889820833898\n",
      "Stiri_pozitive/10.txt  0.5798415536437319     0.42015844263097785\n",
      "Stiri_pozitive/16.txt  0.39977565708334356     0.6002243562429632\n",
      "Stiri_pozitive/23.txt  0.39053702231619386     0.6094629669582451\n",
      "Stiri_pozitive/33.txt  0.023250817164569816     0.9767491678211176\n",
      "Stiri_pozitive/30.txt  0.33852223808610576     0.6614777616390778\n",
      "Stiri_pozitive/18.txt  0.5186166141583369     0.48138338738909137\n",
      "Stiri_pozitive/7.txt  0.459542627454809     0.5404573650366292\n",
      "Stiri_pozitive/22.txt  0.3423647034505848     0.6576352957636118\n",
      "Stiri_pozitive/6.txt  0.49817987329368063     0.5018201214630194\n",
      "Stiri_pozitive/38.txt  0.3314512836559291     0.6685487111971151\n",
      "Stiri_pozitive/29.txt  0.38364758150918143     0.6163524406296866\n",
      "Stiri_pozitive/26.txt  0.3396137908899358     0.6603861937590805\n",
      "Stiri_pozitive/27.txt  0.30909495604665654     0.690905054036836\n",
      "Stiri_pozitive/28.txt  0.09242463341584747     0.907575377422135\n",
      "Stiri_pozitive/0.txt  0.22625972948423245     0.7737402901416872\n",
      "Stiri_pozitive/35.txt  0.1279684346065753     0.872031557891104\n",
      "Stiri_pozitive/1.txt  0.4959899493079772     0.5040100424445887\n",
      "Stiri_pozitive/36.txt  0.4567232637766348     0.5432767320082957\n",
      "Stiri_pozitive/37.txt  0.5851316511909538     0.4148683422636763\n",
      "Stiri_pozitive/21.txt  0.6740296303998382     0.32597037413242186\n",
      "Stiri_pozitive/9.txt  0.38905736960256865     0.6109426314829465\n",
      "Stiri_pozitive/24.txt  0.4134929737240955     0.5865070364031012\n",
      "Stiri_pozitive/13.txt  0.3584644154108612     0.6415355972675019\n",
      "Stiri_pozitive/14.txt  0.41123162655008805     0.58876838311553\n",
      "Stiri_pozitive/40.txt  0.4886342524345649     0.5113657496301299\n",
      "Stiri_pozitive/2.txt  0.1991881753894545     0.8008118140555563\n",
      "Stiri_pozitive/25.txt  0.3677844558239292     0.6322155608723201\n",
      "Stiri_pozitive/5.txt  0.4349969687037073     0.5650030316626014\n",
      "Stiri_pozitive/32.txt  0.4185029549927736     0.5814970342552315\n",
      "Stiri_pozitive/4.txt  0.2698165061200089     0.7301834867839966\n",
      "Stiri_pozitive/20.txt  0.3397847052434447     0.6602152941858817\n",
      "Stiri_pozitive/19.txt  0.20222825085919144     0.7977717432419696\n",
      "Stiri_pozitive/15.txt  0.4738679492501947     0.5261320571734566\n",
      "Total stiri pozitive : 42\n",
      "Corecte stiri pozitive : 38\n",
      "Acuratete Pozitive: 0.9047619047619048\n",
      "\n",
      "---Stiri Negative---\n",
      "Stiri_negative/34.txt  0.5054745464882953     0.49452545308897683\n",
      "Stiri_negative/42.txt  0.44192905565525625     0.558070930632505\n",
      "Stiri_negative/12.txt  0.4537590058734182     0.5462410056688747\n",
      "Stiri_negative/41.txt  0.6373617160492219     0.3626382934072843\n",
      "Stiri_negative/11.txt  0.5972410376825833     0.4027589632529918\n",
      "Stiri_negative/31.txt  0.3513866048488839     0.6486133986390105\n",
      "Stiri_negative/3.txt  0.45252300455723465     0.5474770017141519\n",
      "Stiri_negative/39.txt  0.42463746609151826     0.5753625493872073\n",
      "Stiri_negative/17.txt  0.32575525633990765     0.6742447352138432\n",
      "Stiri_negative/8.txt  0.40096160754277976     0.5990384058133477\n",
      "Stiri_negative/10.txt  0.7510717286438239     0.2489282709490406\n",
      "Stiri_negative/16.txt  0.5663829629520213     0.43361705911420556\n",
      "Stiri_negative/23.txt  0.7392648141021314     0.26073517654415057\n",
      "Stiri_negative/33.txt  0.6472857697379022     0.35271422423067544\n",
      "Stiri_negative/30.txt  0.4814532062253066     0.5185468052843569\n",
      "Stiri_negative/18.txt  0.5319441213029098     0.46805588088252326\n",
      "Stiri_negative/44.txt  0.3468247205018997     0.6531752927617712\n",
      "Stiri_negative/7.txt  0.5308085331632718     0.46919146118443306\n",
      "Stiri_negative/22.txt  0.5171173299629677     0.48288266272827757\n",
      "Stiri_negative/6.txt  0.8123618447022631     0.18763814765335507\n",
      "Stiri_negative/38.txt  0.6034394051717675     0.39656059430993124\n",
      "Stiri_negative/29.txt  0.5330002098908153     0.46699980687481\n",
      "Stiri_negative/26.txt  0.40260902371737034     0.5973909869052396\n",
      "Stiri_negative/27.txt  0.5800683211127083     0.4199316826560003\n",
      "Stiri_negative/28.txt  0.6654158225259685     0.33458416427679377\n",
      "Stiri_negative/0.txt  0.526622216046696     0.4733778114469958\n",
      "Stiri_negative/35.txt  0.3562302488631978     0.643769757582899\n",
      "Stiri_negative/1.txt  0.8104048811080979     0.18959511257708073\n",
      "Stiri_negative/36.txt  0.5165467171407327     0.48345328446447366\n",
      "Stiri_negative/37.txt  0.6626622567824005     0.3373377451855006\n",
      "Stiri_negative/21.txt  0.7167764308893285     0.28322357430136036\n",
      "Stiri_negative/9.txt  0.616469656561045     0.38353033354130867\n",
      "Stiri_negative/24.txt  0.6179106512572616     0.38208933803252876\n",
      "Stiri_negative/13.txt  0.5507442149358827     0.4492557869166941\n",
      "Stiri_negative/14.txt  0.7170785308202617     0.2829214757069563\n",
      "Stiri_negative/40.txt  0.6323321667867093     0.3676678447259797\n",
      "Stiri_negative/2.txt  0.6415364012731496     0.35846359001604156\n",
      "Stiri_negative/25.txt  0.39502884793010623     0.6049711490219289\n",
      "Stiri_negative/43.txt  0.6313826356155329     0.36861736106168586\n",
      "Stiri_negative/5.txt  0.7632322514057159     0.23676774606108666\n",
      "Stiri_negative/32.txt  0.44351464970618165     0.5564853422423844\n",
      "Stiri_negative/4.txt  0.410618374828954     0.5893816108236442\n",
      "Stiri_negative/20.txt  0.717485457604778     0.28251455692070476\n",
      "Stiri_negative/19.txt  0.5929884895878402     0.4070115180167937\n",
      "Stiri_negative/15.txt  0.35550641859119586     0.6444935686479916\n",
      "Total stiri negative : 45\n",
      "Corecte stiri negative : 30\n",
      "Acuratete negative: 0.6666666666666666\n",
      "\n",
      "Total stiri :87\n",
      "Total corecte :68\n",
      "Acuratete :0.7816091954022989\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('./Model-200-drop30--perf/')\n",
    "\n",
    "count=0;\n",
    "\n",
    "pozitive_total=0\n",
    "negative_total=0\n",
    "pozitive_corecte=0\n",
    "negative_corecte=0\n",
    "neutre_total=0\n",
    "neutre_corecte=0\n",
    "txtfiles = []\n",
    "for file in glob.glob(\"Stiri_pozitive/*.txt\"):\n",
    "    txtfiles.append(file)\n",
    "    \n",
    "\n",
    "print(\"---Stiri Pozitive---\")    \n",
    "for file in txtfiles:\n",
    "    with open(file, \"r\") as fis:\n",
    "        stire = fis.read()\n",
    "        \n",
    "        paragrafe=str(stire).split('\\n')\n",
    "        while(\"\" in paragrafe) :\n",
    "            paragrafe.remove(\"\")\n",
    "            \n",
    "        paragrafe=list(map(clean_punct, paragrafe))\n",
    "        paragrafe=list(map(clean_stop, paragrafe))\n",
    "        #paragrafe=list(map(clean_stem, paragrafe))\n",
    "        \n",
    "        X_train = tokenizer.texts_to_sequences(paragrafe)\n",
    "        X_train = pad_sequences(X_train, maxlen = 128)\n",
    "        \n",
    "        results=model.predict(X_train)\n",
    "        \n",
    "        sum_poz=0\n",
    "        sum_neg=0\n",
    "        nr_paragrafe=0\n",
    "        for i in range(0,len(paragrafe)):\n",
    "            if np.count_nonzero(X_train[i]) > 2:\n",
    "                nr_paragrafe+=1*len(str(paragrafe[i]).split())\n",
    "                sum_neg+=results[i][0]*len(str(paragrafe[i]).split())\n",
    "                sum_poz+=results[i][1]*len(str(paragrafe[i]).split())\n",
    "        \n",
    "        print(str(file)+\"  \"+str(sum_neg/nr_paragrafe)+\"     \"+str(sum_poz/nr_paragrafe))\n",
    "        \n",
    "        pozitive_total+=1\n",
    "        if sum_neg < sum_poz:\n",
    "            pozitive_corecte+=1\n",
    "\n",
    "     \n",
    "print(\"Total stiri pozitive : \"+str(pozitive_total))\n",
    "print(\"Corecte stiri pozitive : \"+str(pozitive_corecte)) \n",
    "print(\"Acuratete Pozitive: \"+str(pozitive_corecte/pozitive_total))\n",
    "print(\"\")    \n",
    "\n",
    "txtfiles = []\n",
    "for file in glob.glob(\"Stiri_negative/*.txt\"):\n",
    "    txtfiles.append(file)\n",
    "print(\"---Stiri Negative---\")    \n",
    "for file in txtfiles:\n",
    "    with open(file, \"r\") as fis:\n",
    "        stire = fis.read()\n",
    "        \n",
    "        paragrafe=str(stire).split('\\n')\n",
    "        while(\"\" in paragrafe) :\n",
    "            paragrafe.remove(\"\")\n",
    "            \n",
    "        paragrafe=list(map(clean_punct, paragrafe))\n",
    "        paragrafe=list(map(clean_stop, paragrafe))\n",
    "        #paragrafe=list(map(clean_stem, paragrafe))\n",
    "        \n",
    "        X_train = tokenizer.texts_to_sequences(paragrafe)\n",
    "        X_train = pad_sequences(X_train, maxlen = 128)\n",
    "        \n",
    "        results=model.predict(X_train)\n",
    "        \n",
    "        sum_poz=0\n",
    "        sum_neg=0\n",
    "        nr_paragrafe=0\n",
    "        for i in range(0,len(paragrafe)):\n",
    "            if np.count_nonzero(X_train[i]) > 2:\n",
    "                nr_paragrafe+=1*len(str(paragrafe[i]).split())\n",
    "                sum_neg+=results[i][0]*len(str(paragrafe[i]).split())\n",
    "                sum_poz+=results[i][1]*len(str(paragrafe[i]).split())\n",
    "                \n",
    "        print(str(file)+\"  \"+str(sum_neg/nr_paragrafe)+\"     \"+str(sum_poz/nr_paragrafe))\n",
    "        \n",
    "        negative_total+=1\n",
    "        if sum_neg > sum_poz:\n",
    "            negative_corecte+=1\n",
    "    \n",
    "print(\"Total stiri negative : \"+str(negative_total))\n",
    "print(\"Corecte stiri negative : \"+str(negative_corecte)) \n",
    "print(\"Acuratete negative: \"+str(negative_corecte/negative_total))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Total stiri :\" + str(pozitive_total+negative_total+neutre_total))\n",
    "print(\"Total corecte :\" + str(pozitive_corecte+negative_corecte+neutre_corecte))\n",
    "print(\"Acuratete :\" + str((pozitive_corecte+negative_corecte+neutre_corecte)/(pozitive_total+negative_total+neutre_total)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db38bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
