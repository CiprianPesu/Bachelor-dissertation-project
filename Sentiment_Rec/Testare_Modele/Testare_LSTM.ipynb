{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a6b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import glob\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3112d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter=PorterStemmer()\n",
    "stopwords=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y']\n",
    "import pickle\n",
    "with open('tokenizer-200-nou.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d9e5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punct(a):        \n",
    "    return a.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "def clean_stop(a):\n",
    "    a_token=a.split()\n",
    "    \n",
    "    str1=\"\"\n",
    "    for tk in a_token:\n",
    "        if tk in stopwords:\n",
    "            continue\n",
    "        else:\n",
    "            str1 += tk+\" \"\n",
    "            \n",
    "    return str1\n",
    "\n",
    "def clean_stem(a):\n",
    "    a_token=a.split()\n",
    "    \n",
    "    str1=\"\"\n",
    "    for tk in a_token:\n",
    "            str1 += porter.stem(tk)+\" \"\n",
    "            \n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a200d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "---Stiri Pozitive---\n",
      "Stiri_pozitive/34.txt  0.38680820778012276     0.6131917963425318\n",
      "Stiri_pozitive/42.txt  0.5682807095233194     0.43171929820810345\n",
      "Stiri_pozitive/12.txt  0.5343543034046888     0.46564570939119315\n",
      "Stiri_pozitive/41.txt  0.4138100951289137     0.5861899075408776\n",
      "Stiri_pozitive/45.txt  0.5205604815188122     0.4794395124291804\n",
      "Stiri_pozitive/11.txt  0.5959234020289252     0.404076606429675\n",
      "Stiri_pozitive/31.txt  0.4165042186498331     0.5834957878002132\n",
      "Stiri_pozitive/3.txt  0.42192477621866165     0.5780752184967654\n",
      "Stiri_pozitive/39.txt  0.4803257678068427     0.5196742233808874\n",
      "Stiri_pozitive/17.txt  0.3046479677542662     0.6953520301060799\n",
      "Stiri_pozitive/48.txt  0.41620975180141967     0.5837902405257087\n",
      "Stiri_pozitive/8.txt  0.3982580633245293     0.6017419379457851\n",
      "Stiri_pozitive/10.txt  0.43815935008832946     0.5618406522092481\n",
      "Stiri_pozitive/16.txt  0.5231195652081321     0.4768804295958641\n",
      "Stiri_pozitive/47.txt  0.4856700067156858     0.5143299916174507\n",
      "Stiri_pozitive/23.txt  0.26535412214735415     0.7346458977468663\n",
      "Stiri_pozitive/33.txt  0.07134388676174333     0.9286561212807058\n",
      "Stiri_pozitive/49.txt  0.4923389173087443     0.5076610792703665\n",
      "Stiri_pozitive/30.txt  0.27498564301370243     0.7250143637075153\n",
      "Stiri_pozitive/18.txt  0.5291834988105605     0.4708165113726113\n",
      "Stiri_pozitive/44.txt  0.593318829636374     0.4066811609500183\n",
      "Stiri_pozitive/7.txt  0.409932160227817     0.5900678451182634\n",
      "Stiri_pozitive/22.txt  0.4257413677498698     0.5742586349695921\n",
      "Stiri_pozitive/6.txt  0.582958792589863     0.41704120475678974\n",
      "Stiri_pozitive/38.txt  0.4177135604805027     0.5822864359889934\n",
      "Stiri_pozitive/29.txt  0.2574220699923379     0.7425778985023499\n",
      "Stiri_pozitive/26.txt  0.4774606423515852     0.5225393617031525\n",
      "Stiri_pozitive/27.txt  0.38129455122529277     0.6187054504029799\n",
      "Stiri_pozitive/28.txt  0.14261745928400538     0.8573825310279684\n",
      "Stiri_pozitive/0.txt  0.419872703348718     0.5801272861114363\n",
      "Stiri_pozitive/46.txt  0.22127331759622124     0.778726681036518\n",
      "Stiri_pozitive/35.txt  0.2144517940296619     0.7855482018656201\n",
      "Stiri_pozitive/1.txt  0.44630412039573136     0.5536958811848421\n",
      "Stiri_pozitive/36.txt  0.4910908534979591     0.5089091333703926\n",
      "Stiri_pozitive/37.txt  0.6203126881876563     0.3796872849393095\n",
      "Stiri_pozitive/21.txt  0.6866483861495826     0.3133516256295314\n",
      "Stiri_pozitive/9.txt  0.4012494667415099     0.5987505218573317\n",
      "Stiri_pozitive/24.txt  0.5105702367608759     0.489429751584005\n",
      "Stiri_pozitive/13.txt  0.2801908430802985     0.7198091563005737\n",
      "Stiri_pozitive/14.txt  0.5929894324938456     0.40701057546337444\n",
      "Stiri_pozitive/40.txt  0.4512529760157153     0.5487470291681209\n",
      "Stiri_pozitive/2.txt  0.13892551023690475     0.8610744777889479\n",
      "Stiri_pozitive/25.txt  0.4586144393215531     0.5413855661719625\n",
      "Stiri_pozitive/43.txt  0.39372068477120803     0.606279304687013\n",
      "Stiri_pozitive/5.txt  0.3963924508816498     0.6036075467336065\n",
      "Stiri_pozitive/32.txt  0.4432327420773556     0.5567672696899608\n",
      "Stiri_pozitive/4.txt  0.3328306236163488     0.6671693637866198\n",
      "Stiri_pozitive/20.txt  0.37303831456880804     0.6269616692350088\n",
      "Stiri_pozitive/19.txt  0.25426075794635516     0.7457392474222823\n",
      "Stiri_pozitive/15.txt  0.4908908754757278     0.5091091283346147\n",
      "Total stiri pozitive : 50\n",
      "Corecte stiri pozitive : 38\n",
      "Acuratete Pozitive: 0.76\n",
      "\n",
      "---Stiri Negative---\n",
      "Stiri_negative/34.txt  0.5877490748539038     0.412250899280428\n",
      "Stiri_negative/42.txt  0.5607679970193618     0.4392319823255633\n",
      "Stiri_negative/12.txt  0.5590073268413543     0.440992679476738\n",
      "Stiri_negative/41.txt  0.5861650578534374     0.4138349468389956\n",
      "Stiri_negative/45.txt  0.631367511311431     0.36863248154842926\n",
      "Stiri_negative/11.txt  0.5861915718184577     0.41380841702222826\n",
      "Stiri_negative/31.txt  0.39529162768310716     0.6047083681937561\n",
      "Stiri_negative/3.txt  0.5268107650642709     0.47318922817100617\n",
      "Stiri_negative/39.txt  0.5057809370068403     0.4942190656199669\n",
      "Stiri_negative/17.txt  0.5251066481841983     0.4748933479665584\n",
      "Stiri_negative/48.txt  0.6571125795764308     0.3428874235480062\n",
      "Stiri_negative/8.txt  0.6306015781847089     0.36939841742890006\n",
      "Stiri_negative/10.txt  0.8937333617054048     0.10626663623856065\n",
      "Stiri_negative/16.txt  0.7116764779858942     0.288323530780414\n",
      "Stiri_negative/47.txt  0.5172030528914844     0.48279694821817654\n",
      "Stiri_negative/23.txt  0.7668473776429892     0.23315262839508552\n",
      "Stiri_negative/33.txt  0.7274217729767164     0.27257824573843253\n",
      "Stiri_negative/49.txt  0.6005769085268773     0.3994230745888468\n",
      "Stiri_negative/30.txt  0.7247535813376944     0.27524642852676284\n",
      "Stiri_negative/18.txt  0.5967681475920104     0.40323184697273\n",
      "Stiri_negative/44.txt  0.4384359889829219     0.5615640148747391\n",
      "Stiri_negative/7.txt  0.6822407055346109     0.31775929614506326\n",
      "Stiri_negative/22.txt  0.487124801438472     0.5128752078652987\n",
      "Stiri_negative/6.txt  0.7482331470917847     0.25176684810953626\n",
      "Stiri_negative/38.txt  0.7030596263706684     0.29694038471207024\n",
      "Stiri_negative/29.txt  0.6537970437575843     0.3462029587733382\n",
      "Stiri_negative/26.txt  0.6529051179531962     0.34709489077795297\n",
      "Stiri_negative/27.txt  0.7407497028996061     0.2592503033526294\n",
      "Stiri_negative/28.txt  0.525339200383141     0.47466079478051726\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('./Modele_LSTM/Model-200-l3-2')\n",
    "\n",
    "count=0;\n",
    "\n",
    "pozitive_total=0\n",
    "negative_total=0\n",
    "pozitive_corecte=0\n",
    "negative_corecte=0\n",
    "neutre_total=0\n",
    "neutre_corecte=0\n",
    "txtfiles = []\n",
    "for file in glob.glob(\"Stiri_pozitive/*.txt\"):\n",
    "    txtfiles.append(file)\n",
    "    \n",
    "\n",
    "print(\"---Stiri Pozitive---\")    \n",
    "for file in txtfiles:\n",
    "    with open(file, \"r\") as fis:\n",
    "        stire = fis.read()\n",
    "        \n",
    "        paragrafe=str(stire).split('\\n')\n",
    "        while(\"\" in paragrafe) :\n",
    "            paragrafe.remove(\"\")\n",
    "            \n",
    "        paragrafe=list(map(clean_punct, paragrafe))\n",
    "        paragrafe=list(map(clean_stop, paragrafe))\n",
    "        paragrafe=list(map(clean_stem, paragrafe))\n",
    "        \n",
    "        while(\"\" in paragrafe) :\n",
    "            paragrafe.remove(\"\")\n",
    "        \n",
    "        X_train = tokenizer.texts_to_sequences(paragrafe)\n",
    "        X_train = pad_sequences(X_train, maxlen = 128)\n",
    "        \n",
    "        results=model.predict(X_train)\n",
    "        \n",
    "        sum_poz=0\n",
    "        sum_neg=0\n",
    "        nr_paragrafe=0\n",
    "        for i in range(0,len(paragrafe)):\n",
    "            if np.count_nonzero(X_train[i]) > 2:\n",
    "                nr_paragrafe+=1*len(str(paragrafe[i]).split())\n",
    "                sum_neg+=results[i][0]*len(str(paragrafe[i]).split())\n",
    "                sum_poz+=results[i][1]*len(str(paragrafe[i]).split())\n",
    "        \n",
    "        print(str(file)+\"  \"+str(sum_neg/nr_paragrafe)+\"     \"+str(sum_poz/nr_paragrafe))\n",
    "        \n",
    "        pozitive_total+=1\n",
    "        if sum_neg/nr_paragrafe < sum_poz/nr_paragrafe:\n",
    "            pozitive_corecte+=1\n",
    "\n",
    "     \n",
    "print(\"Total stiri pozitive : \"+str(pozitive_total))\n",
    "print(\"Corecte stiri pozitive : \"+str(pozitive_corecte)) \n",
    "print(\"Acuratete Pozitive: \"+str(pozitive_corecte/pozitive_total))\n",
    "print(\"\")    \n",
    "\n",
    "txtfiles = []\n",
    "for file in glob.glob(\"Stiri_negative/*.txt\"):\n",
    "    txtfiles.append(file)\n",
    "print(\"---Stiri Negative---\")    \n",
    "for file in txtfiles:\n",
    "    with open(file, \"r\") as fis:\n",
    "        stire = fis.read()\n",
    "        \n",
    "        paragrafe=str(stire).split('\\n')\n",
    "        while(\"\" in paragrafe) :\n",
    "            paragrafe.remove(\"\")\n",
    "            \n",
    "        paragrafe=list(map(clean_punct, paragrafe))\n",
    "        paragrafe=list(map(clean_stop, paragrafe))\n",
    "        paragrafe=list(map(clean_stem, paragrafe))\n",
    "        \n",
    "        while(\"\" in paragrafe) :\n",
    "            paragrafe.remove(\"\")\n",
    "        \n",
    "        X_train = tokenizer.texts_to_sequences(paragrafe)\n",
    "        X_train = pad_sequences(X_train, maxlen = 128)\n",
    "        \n",
    "        results=model.predict(X_train)\n",
    "        \n",
    "        sum_poz=0\n",
    "        sum_neg=0\n",
    "        nr_paragrafe=0\n",
    "        for i in range(0,len(paragrafe)):\n",
    "            if np.count_nonzero(X_train[i]) > 2:\n",
    "                nr_paragrafe+=1*len(str(paragrafe[i]).split())\n",
    "                sum_neg+=results[i][0]*len(str(paragrafe[i]).split())\n",
    "                sum_poz+=results[i][1]*len(str(paragrafe[i]).split())\n",
    "                \n",
    "        print(str(file)+\"  \"+str(sum_neg/nr_paragrafe)+\"     \"+str(sum_poz/nr_paragrafe))\n",
    "        \n",
    "        negative_total+=1\n",
    "        if sum_neg/nr_paragrafe> sum_poz/nr_paragrafe:\n",
    "            negative_corecte+=1\n",
    "    \n",
    "print(\"Total stiri negative : \"+str(negative_total))\n",
    "print(\"Corecte stiri negative : \"+str(negative_corecte)) \n",
    "print(\"Acuratete negative: \"+str(negative_corecte/negative_total))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Total stiri :\" + str(pozitive_total+negative_total+neutre_total))\n",
    "print(\"Total corecte :\" + str(pozitive_corecte+negative_corecte+neutre_corecte))\n",
    "print(\"Acuratete :\" + str((pozitive_corecte+negative_corecte+neutre_corecte)/(pozitive_total+negative_total+neutre_total)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db38bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b586e4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
