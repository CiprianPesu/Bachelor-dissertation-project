{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "from transformers import AdamW\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4effb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "  for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))\n",
    "else:\n",
    "  print(\"You are running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3bed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datasets/Stem-Cuvinte-Eliminate/train-punct-stop-stem-200.csv\")\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f623596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a8b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e903850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poz=df[df['sentiment'] == 1]\n",
    "df_neg=df[df['sentiment'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poz=df_poz.sample(1000)\n",
    "df_neg=df_neg.sample(1000)\n",
    "df = pd.concat([df_poz,df_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c66935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d11fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "N_EPOCHS = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =df[2000:].text\n",
    "X_test =df[:2000].text\n",
    "y_train = df[2000:].sentiment\n",
    "y_test = df[:2000].sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25345150",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f509f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = X_train.apply(lambda s: len([x for x in s.split()])).max()\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58211017",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "#tokenize the text (padding to max sequence in batch)\n",
    "train_encodings = tokenizer(list(X_train.values), truncation=True, padding=\"max_length\", max_length=128)\n",
    "test_encodings = tokenizer(list(X_test.values), truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "#print the first paragraph and it transformation\n",
    "print(f'First paragraph: \\'{X_train[:1]}\\'')\n",
    "print(f'Input ids: {train_encodings[\"input_ids\"][0]}')\n",
    "print(f'Attention mask: {train_encodings[\"attention_mask\"][0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3363dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings),\n",
    "                                                    list(y_train.values)))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings),\n",
    "                                                    list(y_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "optimizerr = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "losss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) # Computes the crossentropy loss between the labels and predictions. \n",
    "model.compile(optimizer=optimizerr,                                     \n",
    "              loss=losss,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset.shuffle(len(X_train)).batch(BATCH_SIZE), \n",
    "          epochs=N_EPOCHS,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          validation_data=(test_encodings,y_test.values)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset.shuffle(len(X_test)).batch(BATCH_SIZE), return_dict=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82f96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd49b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(text_list, model, tokenizer):\n",
    "  \"\"\"\n",
    "  To get array with predicted probabilities for 0 - instructions, 1- ingredients classes \n",
    "  for each paragraph in the list of strings\n",
    "  :param text_list: list[str]\n",
    "  :param model: transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification\n",
    "  :param tokenizer: transformers.models.distilbert.tokenization_distilbert.DistilBertTokenizer\n",
    "  :return res: numpy.ndarray\n",
    "  \"\"\"\n",
    "     \n",
    "  encodings = tokenizer(text_list, max_length=MAX_LEN, truncation=True, padding=True)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((dict(encodings))) \n",
    "  preds = model.predict(dataset.batch(1)).logits\n",
    "  res = tf.nn.softmax(preds, axis=1).numpy()\n",
    "    \n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc478e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = [\"this is good\"]\n",
    "predict_proba(string1, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33689e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints-13000/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_until_layer(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73dd22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
