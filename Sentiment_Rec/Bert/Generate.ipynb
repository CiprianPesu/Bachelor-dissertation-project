{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "222e4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, DistilBertModel\n",
    "from transformers import AdamW\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4effb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "  for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))\n",
    "else:\n",
    "  print(\"You are running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3bed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0d75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Datasets/Stem-Cuvinte-Eliminate/train-punct-stop-stem-200.csv\")\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f623596e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>sound track beauti paint mind well would recom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>im read lot review say best game soundtrack fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>soundtrack favorit music time hand intens sad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>truli like soundtrack enjoy video game music p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>youv play game know divin music everi singl so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          2  sound track beauti paint mind well would recom...\n",
       "1          2  im read lot review say best game soundtrack fi...\n",
       "2          2  soundtrack favorit music time hand intens sad ...\n",
       "3          2  truli like soundtrack enjoy video game music p...\n",
       "4          2  youv play game know divin music everi singl so..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3a8b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e903850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poz=df[df['sentiment'] == 1]\n",
    "df_neg=df[df['sentiment'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e9a776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poz=df_poz.sample(10000)\n",
    "df_neg=df_neg.sample(12000)\n",
    "df = pd.concat([df_poz,df_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c66935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1554501</th>\n",
       "      <td>1</td>\n",
       "      <td>give credit rabbi tri answer question god good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>1</td>\n",
       "      <td>would good time america wake embrac tremend ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559246</th>\n",
       "      <td>1</td>\n",
       "      <td>book provid exampl graph help demonstr lot det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861796</th>\n",
       "      <td>1</td>\n",
       "      <td>ye im not exagger show ultim diva put lot effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004966</th>\n",
       "      <td>1</td>\n",
       "      <td>love fresh butter caraf great hand would recom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text\n",
       "1554501          1  give credit rabbi tri answer question god good...\n",
       "2293             1  would good time america wake embrac tremend ta...\n",
       "559246           1  book provid exampl graph help demonstr lot det...\n",
       "861796           1  ye im not exagger show ultim diva put lot effo...\n",
       "1004966          1  love fresh butter caraf great hand would recom..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d11fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "N_EPOCHS = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "103f3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =df[2000:].text\n",
    "X_test =df[:2000].text\n",
    "y_train = df[2000:].sentiment\n",
    "y_test = df[:2000].sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9be6a2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1554501    give credit rabbi tri answer question god good...\n",
       "2293       would good time america wake embrac tremend ta...\n",
       "559246     book provid exampl graph help demonstr lot det...\n",
       "861796     ye im not exagger show ultim diva put lot effo...\n",
       "1004966    love fresh butter caraf great hand would recom...\n",
       "                                 ...                        \n",
       "21203      ive rush fan sinc 12 im 42 watch bluray last n...\n",
       "1137211    game excel graphic great game difficulti level...\n",
       "308097     found book interest elev though sometim langua...\n",
       "88403      moistur great light absorb quickli not greasi ...\n",
       "663149     excel book must read women import recommend na...\n",
       "Name: text, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f509f2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = X_train.apply(lambda s: len([x for x in s.split()])).max()\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58211017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First paragraph: '579674    great product keep motorcycl batteri warm juic...\n",
      "Name: text, dtype: object'\n",
      "Input ids: [101, 2307, 4031, 2562, 5013, 5666, 20464, 23801, 2072, 4010, 18414, 2594, 3191, 2072, 2175, 3147, 3467, 3204, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "#tokenize the text (padding to max sequence in batch)\n",
    "train_encodings = tokenizer(list(X_train.values), truncation=True, padding=\"max_length\", max_length=128)\n",
    "test_encodings = tokenizer(list(X_test.values), truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "#print the first paragraph and it transformation\n",
    "print(f'First paragraph: \\'{X_train[:1]}\\'')\n",
    "print(f'Input ids: {train_encodings[\"input_ids\"][0]}')\n",
    "print(f'Attention mask: {train_encodings[\"attention_mask\"][0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3363dca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 17:41:47.642512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 17:41:47.649884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 17:41:47.650401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 17:41:47.651474: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-22 17:41:47.652014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 17:41:47.652470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 17:41:47.652830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 17:41:48.114348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 17:41:48.114667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 17:41:48.115023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 17:41:48.115309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3368 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings),\n",
    "                                                    list(y_train.values)))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings),\n",
    "                                                    list(y_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "optimizerr = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "losss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) # Computes the crossentropy loss between the labels and predictions. \n",
    "model.compile(optimizer=optimizerr,                                     \n",
    "              loss=losss,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2173737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 17:41:58.447112: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_layer_norm', 'vocab_projector', 'activation_13', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'classifier', 'dropout_19']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.load_weights('./checkpoints-7000/my_checkpoint')\n",
    "optimizerr = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "losss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) # Computes the crossentropy loss between the labels and predictions. \n",
    "model.compile(optimizer=optimizerr,                                     \n",
    "              loss=losss,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0497d699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f2393004ac0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f2393004ac0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 0.3314 - accuracy: 0.8614WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "1250/1250 [==============================] - 666s 524ms/step - loss: 0.3314 - accuracy: 0.8614 - val_loss: 0.3542 - val_accuracy: 0.8570\n",
      "Epoch 2/2\n",
      "1250/1250 [==============================] - 671s 537ms/step - loss: 0.2011 - accuracy: 0.9232 - val_loss: 0.3736 - val_accuracy: 0.8350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2285eec2e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset.shuffle(len(X_train)).batch(BATCH_SIZE), \n",
    "          epochs=N_EPOCHS,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          validation_data=(test_dataset.shuffle(len(X_test)).batch(BATCH_SIZE))\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset.shuffle(len(X_test)).batch(BATCH_SIZE), return_dict=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82f96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd49b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(text_list, model, tokenizer):\n",
    "  \"\"\"\n",
    "  To get array with predicted probabilities for 0 - instructions, 1- ingredients classes \n",
    "  for each paragraph in the list of strings\n",
    "  :param text_list: list[str]\n",
    "  :param model: transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification\n",
    "  :param tokenizer: transformers.models.distilbert.tokenization_distilbert.DistilBertTokenizer\n",
    "  :return res: numpy.ndarray\n",
    "  \"\"\"\n",
    "     \n",
    "  encodings = tokenizer(text_list, max_length=MAX_LEN, truncation=True, padding=True)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((dict(encodings))) \n",
    "  preds = model.predict(dataset.batch(1)).logits\n",
    "  res = tf.nn.softmax(preds, axis=1).numpy()\n",
    "    \n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc478e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "string1 = [\"this is good\"]\n",
    "predict_proba(string1, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33689e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints-150000/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_until_layer(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73dd22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
